#file: noinspection SpellCheckingInspection
services:
  postgresql:
    image: postgres:15-alpine
    container_name: group-purchase-postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres1234
      POSTGRES_DB: group_purchase
      TZ: Asia/Seoul
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init:/docker-entrypoint-initdb.d
    networks:
      - group-purchase-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: group-purchase-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - group-purchase-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: group-purchase-kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - group-purchase-network
    healthcheck:
      test: [ "CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092" ]
      interval: 10s
      timeout: 10s
      retries: 5

  elasticsearch:
    build:
      context: .
      dockerfile: Dockerfile
      tags:
        - elasticsearch-nori:8.18.8
    container_name: group-purchase-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - cluster.name=group-purchase-cluster
      - node.name=group-purchase-node
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - group-purchase-network
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5

  fluent-bit:
    image: fluent/fluent-bit:2.2
    container_name: fluent-bit
    ports:
      - "2020:2020"
    environment:
      KAFKA_BROKERS: kafka:9092
      KAFKA_TOPIC: app-logs
    volumes:
      # Fluent Bit 설정
      - ./fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ./fluent-bit/parsers.conf:/fluent-bit/etc/parsers.conf:ro
      # 애플리케이션 로그 디렉토리 (Spring Boot에서 로그 파일로 남기는 경우)
      - ./logs:/var/log/app:ro
    networks:
      - group-purchase-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:2020/api/v1/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5
    command: [
      "/fluent-bit/bin/fluent-bit",
      "-c", "/fluent-bit/etc/fluent-bit.conf"
    ]
    restart: unless-stopped

volumes:
  kafka_data:
    driver: local
  postgres_data:
    driver: local
  redis_data:
    driver: local
  elasticsearch_data:
    driver: local
  logstash_data:
    driver: local

networks:
  group-purchase-network:
    driver: bridge
